# SCALE-Sim ML Predictor

## é¡¹ç›®æ¦‚è¿°

SCALE-Sim ML Predictor æ˜¯ä¸€ä¸ªæœºå™¨å­¦ä¹ æ¨¡å—ï¼Œç”¨äºé¢„æµ‹ SCALE-Simï¼ˆæ·±åº¦å­¦ä¹ åŠ é€Ÿå™¨ä»¿çœŸå·¥å…·ï¼‰çš„æ€§èƒ½æŒ‡æ ‡ã€‚é€šè¿‡è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œå¯ä»¥åœ¨**æ¯«ç§’çº§**é¢„æµ‹ä»¿çœŸç»“æœï¼Œç›¸æ¯”ä¼ ç»Ÿä»¿çœŸå¿«æ•°åƒå€ã€‚

### æ ¸å¿ƒåŠŸèƒ½

- **æ•°æ®ç”Ÿæˆ**: è‡ªåŠ¨è¿è¡Œ SCALE-Sim ä»¿çœŸå¹¶æ”¶é›†è®­ç»ƒæ•°æ®
- **æ¨¡å‹è®­ç»ƒ**: ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œå­¦ä¹ ç¡¬ä»¶é…ç½®ä¸æ€§èƒ½çš„æ˜ å°„å…³ç³»
- **å¿«é€Ÿé¢„æµ‹**: æ ¹æ®é…ç½®å‚æ•°ç›´æ¥é¢„æµ‹æ€§èƒ½æŒ‡æ ‡ï¼Œæ— éœ€è¿è¡Œä»¿çœŸ
- **è‡ªåŠ¨å»é‡**: æ™ºèƒ½æ£€æµ‹å¹¶è·³è¿‡å·²å­˜åœ¨çš„é…ç½®ç»„åˆ

### é¢„æµ‹æŒ‡æ ‡

ä» `COMPUTE_REPORT.csv` ä¸­æå–ä»¥ä¸‹ 6 ä¸ªå…³é”®æ€§èƒ½æŒ‡æ ‡ï¼š

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| `total_cycles_with_prefetch` | åŒ…å«é¢„å–çš„æ€»å‘¨æœŸæ•° |
| `total_cycles` | ä¸å«é¢„å–çš„æ€»å‘¨æœŸæ•° |
| `stall_cycles` | åœé¡¿å‘¨æœŸæ•° |
| `overall_util_percent` | æ•´ä½“åˆ©ç”¨ç‡ (%) |
| `mapping_efficiency_percent` | æ˜ å°„æ•ˆç‡ (%) |
| `compute_util_percent` | è®¡ç®—åˆ©ç”¨ç‡ (%) |

---

## å®‰è£…ä¾èµ–

```bash
# åœ¨ scale-sim-v3 é¡¹ç›®æ ¹ç›®å½•ä¸‹æ‰§è¡Œ
pip install -r ml_predictor/requirements.txt
```

**ä¾èµ–åŒ…**:
- `torch>=1.9.0` - PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶
- `numpy>=1.19.0` - æ•°å€¼è®¡ç®—
- `pandas>=1.2.0` - æ•°æ®å¤„ç†
- `scikit-learn>=0.24.0` - æ•°æ®é¢„å¤„ç†å’Œè¯„ä¼°

---

## å¿«é€Ÿå¼€å§‹

### 1. ç”Ÿæˆè®­ç»ƒæ•°æ®

```bash
# ç”Ÿæˆ 100 ä¸ªæ ·æœ¬ï¼ˆæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºç§å­ï¼‰
python -m ml_predictor.main generate --num_samples 100 --workers 4

# æŒ‡å®šè¾“å‡ºè·¯å¾„
python -m ml_predictor.main generate --num_samples 100 --output ./data/my_data.csv --workers 4

# ä½¿ç”¨å›ºå®šç§å­ï¼ˆä¾¿äºå¤ç°ï¼‰
python -m ml_predictor.main generate --num_samples 100 --seed 12345 --workers 4
```

### 2. è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python -m ml_predictor.main train --data_path ./data/raw/training_data.csv

# è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
python -m ml_predictor.main train \
  --data_path ./data/raw/training_data.csv \
  --epochs 200 \
  --batch_size 128 \
  --lr 0.0001
```

### 3. é¢„æµ‹

```bash
# å¯¹å•ä¸ªé…ç½®è¿›è¡Œé¢„æµ‹
python -m ml_predictor.main predict \
  --config ./configs/google.cfg \
  --topology ./topologies/ispass25_models/alexnet.csv \
  --output ./results/predictions.csv
```

### 4. è¯„ä¼°æ¨¡å‹

```bash
# åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½
python -m ml_predictor.main evaluate \
  --data_path ./data/raw/test_data.csv \
  --output ./results/evaluation.json
```

---

## æ¨¡å—è¯¦è§£

### ğŸ“ é¡¹ç›®ç»“æ„

```
ml_predictor/
â”œâ”€â”€ __init__.py              # åŒ…åˆå§‹åŒ–
â”œâ”€â”€ config.py                # é…ç½®å‚æ•°
â”œâ”€â”€ data_generation.py       # æ•°æ®ç”Ÿæˆæ¨¡å—
â”œâ”€â”€ data_preprocessing.py    # æ•°æ®é¢„å¤„ç†æ¨¡å—
â”œâ”€â”€ model.py                 # ç¥ç»ç½‘ç»œæ¨¡å‹å®šä¹‰
â”œâ”€â”€ train.py                 # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ predict.py               # æ¨ç†æ¨¡å—
â”œâ”€â”€ evaluate.py              # è¯„ä¼°æ¨¡å—
â”œâ”€â”€ main.py                  # ä¸»å…¥å£CLI
â”œâ”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â””â”€â”€ README.md               # æœ¬æ–‡æ¡£
```

---

### 1ï¸âƒ£ config.py - é…ç½®å‚æ•°

å®šä¹‰æ‰€æœ‰å¯è°ƒçš„è¶…å‚æ•°å’Œé…ç½®ã€‚

#### æ•°æ®ç”Ÿæˆé…ç½®

```python
DATA_GENERATION_CONFIG = {
    "num_samples": 5000,  # é»˜è®¤ç”Ÿæˆæ ·æœ¬æ•°
    
    # ç¡¬ä»¶é…ç½®å‚æ•°èŒƒå›´
    "array_height_range": [64, 128, 256, 512],
    "array_width_range": [64, 128, 256, 512],
    "ifmap_sram_sz_kb_range": [256, 512, 1024, 2048, 4096, 6144],
    "filter_sram_sz_kb_range": [256, 512, 1024, 2048, 4096, 6144],
    "ofmap_sram_sz_kb_range": [256, 512, 1024, 2048],
    "dataflow_options": ["os", "ws", "is"],
    "bandwidth_range": [5, 10, 20, 50, 100],
    
    # å·ç§¯å±‚å‚æ•°èŒƒå›´
    "ifmap_height_range": [7, 13, 14, 27, 28, 56, 112, 224],
    "ifmap_width_range": [7, 13, 14, 27, 28, 56, 112, 224],
    "filter_height_range": [1, 3, 5, 7, 11],
    "filter_width_range": [1, 3, 5, 7, 11],
    "channels_range": [3, 16, 32, 64, 96, 128, 256, 384, 512],
    "num_filter_range": [16, 32, 64, 96, 128, 256, 384, 512],
    "strides_range": [1, 2, 4],
}
```

#### æ¨¡å‹è®­ç»ƒé…ç½®

```python
MODEL_CONFIG = {
    "hidden_dims": [128, 256, 128, 64],  # éšè—å±‚ç»´åº¦
    "dropout_rate": 0.2,                 # Dropout æ¯”ä¾‹
    "learning_rate": 0.001,              # å­¦ä¹ ç‡
    "batch_size": 64,                    # æ‰¹å¤§å°
    "epochs": 100,                       # æœ€å¤§è®­ç»ƒè½®æ•°
    "early_stopping_patience": 10,       # æ—©åœè€å¿ƒå€¼
    "train_val_test_split": [0.7, 0.15, 0.15],  # æ•°æ®åˆ’åˆ†æ¯”ä¾‹
}
```

**ä¿®æ”¹é…ç½®**: ç›´æ¥ç¼–è¾‘ `config.py` æ–‡ä»¶å³å¯ã€‚

---

### 2ï¸âƒ£ data_generation.py - æ•°æ®ç”Ÿæˆæ¨¡å—

#### å®ç°åŸç†

1. **éšæœºé‡‡æ ·é…ç½®**: ä»é¢„å®šä¹‰èŒƒå›´å†…éšæœºç”Ÿæˆç¡¬ä»¶é…ç½®å’Œå·ç§¯å±‚å‚æ•°
2. **ç”Ÿæˆä¸´æ—¶æ–‡ä»¶**: åˆ›å»ºä¸´æ—¶çš„ `config.cfg`, `topology.csv`, `layout.csv`
3. **è¿è¡Œä»¿çœŸ**: è°ƒç”¨åŸå§‹ SCALE-Sim è¿›è¡Œä»¿çœŸ
4. **è§£æç»“æœ**: æå– `COMPUTE_REPORT.csv` ä¸­çš„æ€§èƒ½æŒ‡æ ‡
5. **ä¿å­˜æ•°æ®**: å°†è¾“å…¥ç‰¹å¾å’Œè¾“å‡ºæŒ‡æ ‡é…å¯¹ä¿å­˜åˆ° CSV

#### æ ¸å¿ƒç±»: `DataGenerator`

```python
class DataGenerator:
    def __init__(self, config=None, seed=None):
        """
        Args:
            config: é…ç½®å­—å…¸ï¼Œé»˜è®¤ä½¿ç”¨ DATA_GENERATION_CONFIG
            seed: éšæœºç§å­ï¼ŒNone æ—¶ä½¿ç”¨å½“å‰æ—¶é—´ï¼ˆæ¯æ¬¡ä¸åŒï¼‰
        """
```

**å…³é”®æ–¹æ³•**:

- `_generate_random_config()`: éšæœºç”Ÿæˆç¡¬ä»¶é…ç½®
- `_generate_random_conv_layer()`: éšæœºç”Ÿæˆå·ç§¯å±‚å‚æ•°
- `_create_config_file()`: åˆ›å»ºä¸´æ—¶ config.cfg
- `_create_topology_file()`: åˆ›å»ºä¸´æ—¶ topology.csv
- `_create_layout_file()`: åˆ›å»ºä¸´æ—¶ layout.csv
- `_run_single_simulation()`: è¿è¡Œå•æ¬¡ä»¿çœŸå¹¶è¿”å›ç»“æœ
- `_get_config_signature()`: ç”Ÿæˆé…ç½®çš„å”¯ä¸€ç­¾åï¼ˆç”¨äºå»é‡ï¼‰
- `_load_existing_configs()`: åŠ è½½å·²å­˜åœ¨çš„é…ç½®ï¼ˆé¿å…é‡å¤ï¼‰
- `generate()`: ä¸»ç”Ÿæˆå‡½æ•°

#### å»é‡æœºåˆ¶

ä½¿ç”¨ MD5 å“ˆå¸Œå¯¹é…ç½®è¿›è¡Œç­¾åï¼Œè‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„é…ç½®ï¼š

```python
def _get_config_signature(self, hw_config, conv_layer):
    sig_parts = [
        hw_config["array_height"],
        hw_config["array_width"],
        # ... æ‰€æœ‰é…ç½®å‚æ•°
    ]
    sig_str = "|".join(map(str, sig_parts))
    return hashlib.md5(sig_str.encode()).hexdigest()
```

#### è¿½åŠ æ¨¡å¼

æ–°æ•°æ®è‡ªåŠ¨è¿½åŠ åˆ°å·²æœ‰æ–‡ä»¶ï¼Œä¸ä¼šè¦†ç›–ï¼š

```python
# æ–‡ä»¶å­˜åœ¨æ—¶è¿½åŠ ï¼Œä¸å­˜åœ¨æ—¶åˆ›å»º
with open(output_file, "a" if file_exists else "w", newline="") as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    if not file_exists:
        writer.writeheader()
    writer.writerows(results)
```

---

### 3ï¸âƒ£ data_preprocessing.py - æ•°æ®é¢„å¤„ç†æ¨¡å—

#### å®ç°åŸç†

1. **One-Hot ç¼–ç **: å°† dataflow (os/ws/is) ç¼–ç ä¸º 3 ä¸ªäºŒè¿›åˆ¶ç‰¹å¾
2. **è¡ç”Ÿç‰¹å¾è®¡ç®—**: è®¡ç®— MACs, æ•°æ®å¤§å°, è®¡ç®—å¼ºåº¦ç­‰
3. **å¯¹æ•°å˜æ¢**: å¯¹å¤§æ•°å€¼ï¼ˆcycles, MACsï¼‰è¿›è¡Œ log1p å˜æ¢
4. **æ ‡å‡†åŒ–**: ä½¿ç”¨ StandardScaler å½’ä¸€åŒ–æ‰€æœ‰ç‰¹å¾

#### æ ¸å¿ƒç±»: `DataPreprocessor`

```python
class DataPreprocessor:
    def __init__(self, scaler_type="standard"):
        self.feature_scaler = StandardScaler()
        self.target_scaler = StandardScaler()
```

**å…³é”®æ–¹æ³•**:

- `_one_hot_encode_dataflow()`: One-Hot ç¼–ç  dataflow
- `_add_derived_features()`: æ·»åŠ è¡ç”Ÿç‰¹å¾
- `preprocess()`: ä¸»é¢„å¤„ç†å‡½æ•°
- `inverse_transform_targets()`: åå½’ä¸€åŒ–é¢„æµ‹ç»“æœ
- `split_data()`: åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
- `save()` / `load()`: ä¿å­˜/åŠ è½½é¢„å¤„ç†å™¨

#### ç‰¹å¾å·¥ç¨‹

**è¾“å…¥ç‰¹å¾** (21 ä¸ª):
```
ç¡¬ä»¶é…ç½® (9):
  - array_height, array_width
  - ifmap_sram_sz_kb, filter_sram_sz_kb, ofmap_sram_sz_kb
  - dataflow_os, dataflow_ws, dataflow_is (One-Hot)
  - bandwidth

å·ç§¯å±‚å‚æ•° (7):
  - ifmap_height, ifmap_width
  - filter_height, filter_width
  - channels, num_filter, strides

è¡ç”Ÿç‰¹å¾ (5):
  - total_macs: ofmap_h Ã— ofmap_w Ã— filter_h Ã— filter_w Ã— channels Ã— num_filter
  - ifmap_size: ifmap_h Ã— ifmap_w Ã— channels
  - filter_size: filter_h Ã— filter_w Ã— channels Ã— num_filter
  - ofmap_size: ofmap_h Ã— ofmap_w Ã— num_filter
  - compute_intensity: total_macs / (ifmap_size + filter_size + ofmap_size)
```

#### æ•°æ®å˜æ¢

```python
# å¯¹å¤§æ•°å€¼è¿›è¡Œ log å˜æ¢
log_features = ['total_macs', 'ifmap_size', 'filter_size', 'ofmap_size']
X[:, log_indices] = np.log1p(X[:, log_indices])

# å¯¹ cycles è¿›è¡Œ log å˜æ¢
log_targets = ['total_cycles_with_prefetch', 'total_cycles', 'stall_cycles']
y[:, cycle_indices] = np.log1p(y[:, cycle_indices])

# StandardScaler æ ‡å‡†åŒ–
X_scaled = (X - mean) / std
y_scaled = (y - mean) / std
```

---

### 4ï¸âƒ£ model.py - ç¥ç»ç½‘ç»œæ¨¡å‹

#### æ¨¡å‹æ¶æ„

```
Input (21 features)
  â†“
Linear(21 â†’ 128) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2)
  â†“
Linear(128 â†’ 256) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2)
  â†“
Linear(256 â†’ 128) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2)
  â†“
Linear(128 â†’ 64) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2)
  â†“
Linear(64 â†’ 6)  # 6 ä¸ªè¾“å‡ºæŒ‡æ ‡
```

#### æ ¸å¿ƒç±»: `ScaleSimPredictor`

```python
class ScaleSimPredictor(nn.Module):
    def __init__(self, input_dim, output_dim=6, 
                 hidden_dims=[128, 256, 128, 64],
                 dropout_rate=0.2):
        # å¤šå±‚ MLP
        # BatchNorm åŠ é€Ÿæ”¶æ•›
        # Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ
```

#### æ‰©å±•æ¨¡å‹: `ScaleSimPredictorWithUncertainty`

å¸¦ä¸ç¡®å®šæ€§ä¼°è®¡çš„æ¨¡å‹ï¼Œå¯ç”¨äºä¸»åŠ¨å­¦ä¹ ï¼š

```python
class ScaleSimPredictorWithUncertainty(nn.Module):
    def forward(self, x):
        features = self.backbone(x)
        mean = self.mean_head(features)      # é¢„æµ‹å‡å€¼
        logvar = self.logvar_head(features)  # é¢„æµ‹å¯¹æ•°æ–¹å·®
        return mean, logvar
```

---

### 5ï¸âƒ£ train.py - è®­ç»ƒè„šæœ¬

#### è®­ç»ƒæµç¨‹

```
1. åŠ è½½æ•°æ® â†’ load_and_preprocess()
2. æ•°æ®é¢„å¤„ç† â†’ DataPreprocessor.preprocess()
3. åˆ’åˆ†æ•°æ®é›† â†’ train/val/test (70%/15%/15%)
4. åˆ›å»ºæ¨¡å‹ â†’ create_model()
5. è®­ç»ƒå¾ªç¯ â†’ Trainer.train()
   - å‰å‘ä¼ æ’­
   - è®¡ç®— MSE Loss
   - åå‘ä¼ æ’­
   - æ¢¯åº¦è£å‰ª (max_norm=1.0)
   - å‚æ•°æ›´æ–°
6. éªŒè¯ â†’ Trainer.validate()
7. å­¦ä¹ ç‡è°ƒåº¦ â†’ ReduceLROnPlateau
8. æ—©åœæ£€æŸ¥ â†’ patience=10
9. ä¿å­˜æœ€ä½³æ¨¡å‹ â†’ save_model()
```

#### æ ¸å¿ƒç±»: `Trainer`

```python
class Trainer:
    def __init__(self, model, device, learning_rate, 
                 batch_size, epochs, early_stopping_patience):
        self.criterion = nn.MSELoss()
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(...)
```

**å…³é”®æ–¹æ³•**:

- `train_epoch()`: è®­ç»ƒä¸€ä¸ª epoch
- `validate()`: éªŒè¯é›†è¯„ä¼°
- `train()`: å®Œæ•´è®­ç»ƒå¾ªç¯
- `evaluate()`: æµ‹è¯•é›†è¯„ä¼°ï¼ˆè®¡ç®— MAE, MAPE, RMSE, RÂ²ï¼‰
- `save_model()`: ä¿å­˜æ¨¡å‹å’Œå…ƒæ•°æ®

#### è¯„ä¼°æŒ‡æ ‡

```python
# Mean Absolute Error
MAE = mean(|pred - true|)

# Mean Absolute Percentage Error
MAPE = mean(|pred - true| / |true|) Ã— 100%

# Root Mean Squared Error
RMSE = sqrt(mean((pred - true)Â²))

# R-squared
RÂ² = 1 - SS_res / SS_tot
```

---

### 6ï¸âƒ£ predict.py - æ¨ç†æ¨¡å—

#### æ¨ç†æµç¨‹

```
1. è§£æ config.cfg â†’ _parse_config_file()
2. è§£æ topology.csv â†’ _parse_topology_file()
3. æ„å»ºè¾“å…¥ DataFrame â†’ _prepare_input()
4. ç‰¹å¾é¢„å¤„ç† â†’ preprocessor.preprocess(fit=False)
5. æ¨¡å‹å‰å‘æ¨ç† â†’ model(X_tensor)
6. åå½’ä¸€åŒ– â†’ inverse_transform_targets()
7. è¾“å‡ºé¢„æµ‹ç»“æœ
```

#### æ ¸å¿ƒç±»: `Predictor`

```python
class Predictor:
    def __init__(self, model_path, preprocessor_path, device):
        # åŠ è½½é¢„å¤„ç†å™¨
        self.preprocessor = DataPreprocessor.load(preprocessor_path)
        
        # åŠ è½½æ¨¡å‹
        checkpoint = torch.load(model_path)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
```

**å…³é”®æ–¹æ³•**:

- `_parse_config_file()`: è§£æ .cfg æ–‡ä»¶
- `_parse_topology_file()`: è§£æ .csv æ–‡ä»¶
- `_prepare_input()`: å‡†å¤‡è¾“å…¥ DataFrame
- `predict_layer()`: é¢„æµ‹å•å±‚æ€§èƒ½
- `predict_from_files()`: ä»æ–‡ä»¶è¯»å–å¹¶é¢„æµ‹
- `predict_batch()`: æ‰¹é‡é¢„æµ‹

---

### 7ï¸âƒ£ evaluate.py - è¯„ä¼°æ¨¡å—

#### è¯„ä¼°åŠŸèƒ½

1. **æ¨¡å‹æ€§èƒ½è¯„ä¼°**: åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—å„ç§æŒ‡æ ‡
2. **ä¸ä»¿çœŸå¯¹æ¯”**: è¿è¡ŒçœŸå®ä»¿çœŸå¹¶å¯¹æ¯”é¢„æµ‹å€¼

#### æ ¸å¿ƒå‡½æ•°

```python
def evaluate_model(data_path, model_path, preprocessor_path):
    """
    åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹
    è¿”å›: {
        'num_samples': N,
        'targets': {
            'total_cycles': {'MAE': ..., 'MAPE': ..., 'RMSE': ..., 'R2': ...},
            ...
        }
    }
    """

def compare_with_simulation(config_path, topology_path):
    """
    è¿è¡ŒçœŸå®ä»¿çœŸå¹¶å¯¹æ¯” ML é¢„æµ‹
    ç”¨äºéªŒè¯æ¨¡å‹å‡†ç¡®æ€§
    """
```

---

### 8ï¸âƒ£ main.py - ä¸»å…¥å£

ç»Ÿä¸€çš„å‘½ä»¤è¡Œæ¥å£ï¼Œæ”¯æŒ 4 ä¸ªå­å‘½ä»¤ï¼š

```bash
python -m ml_predictor.main <command> [options]
```

**å­å‘½ä»¤**:

| å‘½ä»¤ | åŠŸèƒ½ | ç¤ºä¾‹ |
|------|------|------|
| `generate` | ç”Ÿæˆè®­ç»ƒæ•°æ® | `generate --num_samples 5000` |
| `train` | è®­ç»ƒæ¨¡å‹ | `train --data_path ./data/train.csv` |
| `predict` | é¢„æµ‹æ€§èƒ½ | `predict --config ./configs/google.cfg` |
| `evaluate` | è¯„ä¼°æ¨¡å‹ | `evaluate --data_path ./data/test.csv` |

---

## æ•°æ®æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Phase 1: æ•°æ®ç”Ÿæˆ                           â”‚
â”‚                                                         â”‚
â”‚  éšæœºé…ç½® â†’ åˆ›å»ºä¸´æ—¶æ–‡ä»¶ â†’ è¿è¡Œ SCALE-Sim â†’ è§£ææŠ¥å‘Š    â”‚
â”‚     â†“                                                    â”‚
â”‚  training_data.csv (config + topology + metrics)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Phase 2: æ•°æ®é¢„å¤„ç†                         â”‚
â”‚                                                         â”‚
â”‚  One-Hot ç¼–ç  â†’ è®¡ç®—è¡ç”Ÿç‰¹å¾ â†’ Log å˜æ¢ â†’ æ ‡å‡†åŒ–         â”‚
â”‚     â†“                                                    â”‚
â”‚  X (21 features), y (6 targets) - æ ‡å‡†åŒ–åçš„æ•°æ®         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Phase 3: æ¨¡å‹è®­ç»ƒ                           â”‚
â”‚                                                         â”‚
â”‚  åˆ’åˆ†æ•°æ®é›† â†’ åˆ›å»ºç¥ç»ç½‘ç»œ â†’ è®­ç»ƒå¾ªç¯ â†’ æ—©åœ/ä¿å­˜         â”‚
â”‚     â†“                                                    â”‚
â”‚  scalesim_predictor.pt (è®­ç»ƒå¥½çš„æ¨¡å‹)                    â”‚
â”‚  preprocessor.pkl (é¢„å¤„ç†å™¨)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Phase 4: æ¨ç†é¢„æµ‹                           â”‚
â”‚                                                         â”‚
â”‚  config.cfg + topology.csv â†’ ç‰¹å¾æå– â†’ æ¨¡å‹æ¨ç† â†’ ç»“æœ  â”‚
â”‚     â†“                                                    â”‚
â”‚  é¢„æµ‹çš„ 6 ä¸ªæ€§èƒ½æŒ‡æ ‡ (æ¯«ç§’çº§å®Œæˆ)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## é…ç½®å‚æ•°è¯´æ˜

### è°ƒæ•´é‡‡æ ·èŒƒå›´

åœ¨ `config.py` ä¸­ä¿®æ”¹èŒƒå›´ä»¥æ¢ç´¢ä¸åŒçš„è®¾è®¡ç©ºé—´ï¼š

```python
# ä¾‹å¦‚ï¼šåªæ¢ç´¢å¤§å‹é˜µåˆ—
"array_height_range": [256, 512, 1024],
"array_width_range": [256, 512, 1024],

# ä¾‹å¦‚ï¼šåªå…³æ³¨å°å·ç§¯æ ¸
"filter_height_range": [1, 3],
"filter_width_range": [1, 3],
```

### è°ƒæ•´æ¨¡å‹ç»“æ„

```python
MODEL_CONFIG = {
    "hidden_dims": [256, 512, 256, 128],  # æ›´æ·±çš„ç½‘ç»œ
    "dropout_rate": 0.3,                  # æ›´é«˜çš„ dropout
    "learning_rate": 0.0005,              # æ›´å°çš„å­¦ä¹ ç‡
}
```

---

## å¸¸è§é—®é¢˜ (FAQ)

### Q1: æ•°æ®ç”Ÿæˆå¾ˆæ…¢æ€ä¹ˆåŠï¼Ÿ

æŸäº›é…ç½®ç»„åˆï¼ˆç‰¹åˆ«æ˜¯å¤§é˜µåˆ— + å¤§ç‰¹å¾å›¾ï¼‰ä¼šå¯¼è‡´ä»¿çœŸè€—æ—¶å¾ˆé•¿ã€‚

**è§£å†³æ–¹æ¡ˆ**:
1. å‡å°é‡‡æ ·èŒƒå›´ï¼Œé¿å…æç«¯é…ç½®
2. ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œç”Ÿæˆï¼ˆéœ€è¦ä¿®æ”¹ä»£ç ï¼‰
3. å…ˆç”Ÿæˆå°‘é‡æ•°æ®éªŒè¯æµç¨‹ï¼Œå†å¤§è§„æ¨¡ç”Ÿæˆ

### Q2: å¦‚ä½•æé«˜æ¨¡å‹å‡†ç¡®æ€§ï¼Ÿ

1. **å¢åŠ è®­ç»ƒæ•°æ®**: æ›´å¤šæ ·æœ¬ â†’ æ›´å¥½çš„æ³›åŒ–
2. **è°ƒæ•´ç½‘ç»œç»“æ„**: å°è¯•æ›´æ·±/æ›´å®½çš„ç½‘ç»œ
3. **ç‰¹å¾å·¥ç¨‹**: æ·»åŠ æ›´å¤šè¡ç”Ÿç‰¹å¾
4. **è¶…å‚æ•°è°ƒä¼˜**: å­¦ä¹ ç‡ã€batch sizeã€dropout ç­‰

### Q3: é¢„æµ‹ç»“æœä¸åˆç†ï¼Ÿ

æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. è¾“å…¥é…ç½®æ˜¯å¦åœ¨è®­ç»ƒæ•°æ®èŒƒå›´å†…ï¼ˆæ¨¡å‹å¤–æ¨èƒ½åŠ›æœ‰é™ï¼‰
2. é¢„å¤„ç†å™¨æ˜¯å¦æ­£ç¡®åŠ è½½
3. æ¨¡å‹æ˜¯å¦è®­ç»ƒå……åˆ†ï¼ˆæŸ¥çœ‹è®­ç»ƒ lossï¼‰

### Q4: å¦‚ä½•å¤„ç†å·²æœ‰æ•°æ®ï¼Ÿ

æ•°æ®ç”Ÿæˆä¼šè‡ªåŠ¨åŠ è½½å¹¶è·³è¿‡é‡å¤é…ç½®ï¼š

```bash
# è¿½åŠ  100 ä¸ªæ–°æ ·æœ¬åˆ°å·²æœ‰æ–‡ä»¶
python -m ml_predictor.main generate --num_samples 100
```

### Q5: èƒ½å¦é¢„æµ‹å…¶ä»–æŒ‡æ ‡ï¼Ÿ

å¯ä»¥ï¼ä¿®æ”¹ `data_generation.py` ä¸­çš„è§£æé€»è¾‘ï¼Œä» `BANDWIDTH_REPORT.csv` æˆ– `DETAILED_ACCESS_REPORT.csv` æå–æ›´å¤šæŒ‡æ ‡ã€‚

---

## æ€§èƒ½å¯¹æ¯”

| æ–¹æ³• | å•æ¬¡é¢„æµ‹è€—æ—¶ | å‡†ç¡®æ€§ | é€‚ç”¨åœºæ™¯ |
|------|-------------|--------|---------|
| **SCALE-Sim ä»¿çœŸ** | æ•°ç§’ï½æ•°åˆ†é’Ÿ | 100% (ground truth) | ç²¾ç¡®éªŒè¯ |
| **ML é¢„æµ‹** | æ¯«ç§’çº§ | 90-95% MAPE | å¿«é€Ÿè®¾è®¡ç©ºé—´æ¢ç´¢ |

---

## å¼€å‘è€…æŒ‡å—

### æ·»åŠ æ–°ç‰¹å¾

1. åœ¨ `data_generation.py` ä¸­è®¡ç®—æ–°ç‰¹å¾
2. åœ¨ `config.py` çš„ `INPUT_FEATURES` ä¸­æ·»åŠ ç‰¹å¾å
3. åœ¨ `data_preprocessing.py` ä¸­å¤„ç†æ–°ç‰¹å¾

### ä¿®æ”¹æ¨¡å‹æ¶æ„

ç¼–è¾‘ `model.py` ä¸­çš„ `ScaleSimPredictor` ç±»ï¼š

```python
def __init__(self, input_dim, output_dim):
    # æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶ã€æ®‹å·®è¿æ¥ç­‰
    self.attention = nn.MultiheadAttention(...)
```

### è°ƒè¯•æŠ€å·§

```bash
# ç”Ÿæˆå°‘é‡æ ·æœ¬å¿«é€ŸéªŒè¯
python -m ml_predictor.main generate --num_samples 5

# è®­ç»ƒå°‘é‡ epoch
python -m ml_predictor.main train --data_path ./data/raw/training_data.csv --epochs 5
```

---

## å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨æ­¤æ¨¡å—ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{scalesim_ml_predictor,
  title={SCALE-Sim ML Predictor},
  author={Your Name},
  year={2026},
  url={https://github.com/yourusername/scale-sim-v3}
}
```

---

## è®¸å¯è¯

éµå¾ª SCALE-Sim é¡¹ç›®çš„åŸå§‹è®¸å¯è¯ã€‚

---

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ Issue æˆ– Pull Requestã€‚
